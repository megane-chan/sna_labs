---
title: "Lab 2"
author: "Your Name"
date: today
format: 
  pdf:
      toc: true
      toc-depth: 4
      shift-heading-level-by: 2
      fig-pos: "H"
      fig-cap-location: top
      geometry:
        - top=1in
        - right=.8in
        - bottom=1in
        - left=.8in
      link-citations: true
      linkcolor: blue
      include-in-header: 
        text: |
          \usepackage{fancyhdr}
          \usepackage{titling}
          \pagestyle{fancy}
          \fancyhf{}
          \renewcommand\maketitle{
            \fancyhead[C]{
              \thetitle
              \ifx \theauthor\empty  \else \ – \theauthor \fi
              \ifx \thedate\empty  \else \ – \thedate \ \fi
            }
          }
          \fancyfoot[C]{\thepage}
---

```{r}
#| echo: false
#| output: false
#| message: false

# Lab 2: Descriptive Network Analysis

# Start with a clear environment
rm(list=ls())

######################################################################################
# The first time you run this file, you will need to install several packages.
# To do that, run the code section below. It may take a couple minutes.
# You only need to install packages once, next time you should skip the install lines.
list.of.packages <- c("robustbase","igraph","statnet", "kableExtra", "poweRlaw")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

# You need to load packages every time you run the script or restart R.
library(dplyr)
library(igraph)
library(statnet)
library(ggplot2)
library(poweRlaw)
# To check whether your R loads these packages, run the following code
sessionInfo() ## check other attached packages. If igraph is listed there, you're ready!
```

# Lab 2: Descriptive Network Analysis -- Local and Global Properties

## Assignment Description

In Lab 1, we created and visualized semantic networks from both collective and artificial intelligence text sources. In this lab, you will use descriptive network analyses to compare these two networks. We will begin by looking at the local differences in the positions of nodes in the two graphs. This analysis will answer questions like, "are the most central terms in the collective intelligence network also the most central in the artificial intelligence network?" Then we will look at the global differences in the overall structure of the two networks. This analysis will answer questions like, "which of the two networks has a higher density?"

```{r}
#| echo: false
#| output: false
#| message: false

# 1.	For this lab, you will continue using the same dataset that you gathered in Lab 1. You should be able to reload the exact same data using the RData file you generated and submitted in Lab 1.

######################################################################################
#
# Set current directory and load your dataset from lab 1
#
######################################################################################

# In this step you tell R where to look for your files.
# From the menu, select "Session > Set Working Directory... > To Source File Location".

# Alternatively, if you know the filename, you can uncomment the line below and run it.
# setwd("replace this with path to your directory")

# Load the dataset that you generated in lab 1
# Make sure that you put the RData file in your working directory
load('Lab1_Descriptive.RData')
```

# PART I: Local Network Properties **(25 points)**

In this part, you will compute individual-level network measures and identify some key users in your network. Further, you will conclude this lab exercise with discussion in your main findings based on the visualizations, measures and your own analysis.

For **both** the collective and artificial intelligence graphs:

Generate the giant component graph (only the single largest component) for your networks from Lab 1. You will use the giant component graph, rather than the full network, for all analysis in this lab.

```{r}
#| echo: false
#| output: false
#| message: false

# Take out the largest component from the graph
# start with the AI network
gpt_comp <- igraph::components(gpt_graph)
giantGraph_gpt <- gpt_graph %>%
  induced_subgraph(., which(gpt_comp$membership == which.max(gpt_comp$csize)))

# now repeat steps with the collective intelligence network
hmn_comp <- igraph::components(hmn_graph)
giantGraph_hmn <- hmn_graph %>%
  induced_subgraph(., which(hmn_comp$membership == which.max(hmn_comp$csize)))
```

## Briefly describe each centrality measure **(5 points)**

##### How is each computed and what does its number mean in your network?

#### 1. degree

e.g., a high degree centrality score means...

#### 2. betweenness

#### 3. closeness

#### 4. eigenvector

#### 5. Burt's network constraint

## Hubs and authorities **(2 points)**

##### What do hub and authority centralities measure? Why did we exclude them from our analysis?

e.g., a hub is ...

## Top 5 nodes - Collective Intelligence **(3 points)**

##### Provide a table ranking the top 5 'best placed' nodes in your **collective intelligence** network based on each centrality measure.

```{r}
#| echo: false
#| output: false
#| message: false
#| warning: false

# For this part, you switch 'igraph' to the 'sna' package because we are going to use 
# some functions that only are available in sna package
# As a first step, create a 'sna' graph object from an 'igraph' object
sna_gpt <-
  igraph::as_adjacency_matrix(giantGraph_gpt, sparse = FALSE) %>% 
  network::as.network.matrix()
sna_hmn <-
  igraph::as_adjacency_matrix(giantGraph_hmn, sparse = FALSE) %>% 
  network::as.network.matrix()

# this detaching might be a necessary step since the two packages have some same function names
# R is often confused
# detach('package:igraph')
# library(statnet)

# We will compute centralities based on 'network' package
# First, create a dataframe to store the centrality information
centralities_gpt <- data.frame('node_name' = as.character(network.vertex.names(sna_gpt)))
centralities_hmn <- data.frame('node_name' = as.character(network.vertex.names(sna_hmn)))
```

#### 1. degree

```{r}
# We will provide the full code for you to complete the first couple calculations.

# Calculate degree centrality for the nodes in our undirected graph
centralities_hmn$degree <- sna::degree(sna_hmn, gmode = 'graph') 
# note that the default setting for gmode is 'digraph'
# try running ?degree() for the sna package to get more info on what this means!

centralities_hmn |> 
  dplyr::slice_max(order_by = degree, n = 5) |> # function selects top n = 5 rows, ordered by degree
  kableExtra::kable() ## this functions renders nice table

## note, that you might get more than 5 rows, if multiple nodes have the same degree
```

#### 2. betweenness

```{r}
# Feel free to modify this code if you prefer.

# Calculate betweenness centrality and store it in the data.frame called 'centralities_'
centralities_hmn$betweenness <- sna::betweenness(sna_hmn)

centralities_hmn |> 
  dplyr::slice_max(order_by = betweenness, n = 5) # function selects top n = 5 rows, ordered by betweenness
## make a nice table if you want
```

#### 3. closeness

```{r}
# Calculate closeness centrality and store it in the data.frame called 'centralities'
# using 'igraph' because the code implemented in 'sna' is unreliable
# Note, using "igraph::" allows calling for any igraph function without loading the package
centralities_hmn$closeness <-
  igraph::closeness(
    giantGraph_hmn, 
    mode = 'all'
    )

## now write your code here to select top 5 nodes
## (Tip: copy it from the previous chunk, but change the name of a column)
```

#### 4. eigenvector

```{r}
# Calculate eigenvector centrality and store it in the data.frame called 'centralities'
# using 'igraph' because the code implemented in 'sna' is unreliable
centralities_hmn$eigen <-
  igraph::eigen_centrality(giantGraph_hmn)$vector
```

#### 5. Burt's network constraint

```{r}
# Calculate Burt's network constraint and store it in the data.frame called 'centralities'
# using 'igraph' because 'sna' doesn't have the function
centralities_hmn$netconstraint <- igraph::constraint(giantGraph_hmn)
help(constraint) # Be careful with the interpretation for constraint: High constraint = redundant contacts, low constraint = acting as a broker
help(slice) # This could help you with generating the right table!
```

## Top 5 nodes - Artificial Intelligence **(3 points)**

##### Provide a table ranking the top 5 'best placed' nodes in your **artificial intelligence** network based on each centrality measure.

#### 1. degree

```{r}
#| message: false
#| warning: false

# Calculate degree centrality for the nodes in our undirected graph
centralities_gpt$degree <- sna::degree(sna_gpt, gmode = 'graph')

centralities_gpt |>
  dplyr::slice_max(order_by = degree, n = 5) |> # function selects top n = 5 rows, ordered by degree
  kableExtra::kable() ## this functions renders nice table

## note, that you might get more than 5 rows, if multiple nodes have the same degree
```

#### 2. betweenness

```{r}

```

#### 3. closeness

```{r}

```

#### 4. eigenvector

```{r}

```

#### 5. Burt's network constraint

```{r}

```

```{r}
#| echo: false
#| output: false
#| message: false

## For curious ones!

## Calculate authority and store it in the data.frame called 'centralities'
## using 'igraph' because 'sna' doesn't have the function
# centralities_gpt$authority <- igraph::authority_score(giantGraph_gpt, scale = TRUE)$`vector`
# centralities_hmn$authority <- igraph::authority_score(giantGraph_hmn, scale = TRUE)$`vector`

## Calculate hub and store it in the data.frame called 'centralities'
## using 'igraph' because 'sna' doesn't have the function
# centralities_gpt$hub <- igraph::hub_score(giantGraph_gpt, scale = TRUE)$`vector`
# centralities_hmn$hub <- igraph::hub_score(giantGraph_hmn, scale = TRUE)$`vector`

## FYI if you had a directed graph (in another context)
## You can calculate indegree and outdegree separately as follows:
# centralities_gpt$in_degree <- degree(sna_gpt, cmode = 'indegree')
# centralities_hmn$in_degree <- degree(sna_hmn, cmode = 'indegree')
# centralities_gpt$out_degree <- degree(sna_gpt, cmode = 'outdegree')
# centralities_hmn$out_degree <- degree(sna_hmn, cmode = 'outdegree')

## Similarly, you can calculate incloseness and outcloseness separately as follows:
# centralities_gpt$incloseness <- igraph::closeness(giantGraph_gpt, mode = 'in')
# centralities_gpt$outcloseness <- igraph::closeness(giantGraph_gpt, mode = 'out')
# centralities_hmn$incloseness <- igraph::closeness(giantGraph_hmn, mode = 'in')
# centralities_hmn$outcloseness <- igraph::closeness(giantGraph_hmn, mode = 'out')
```

## Interpreting local network centrality metrics **(8 points)**

##### How does the centrality of nodes vary with different types of centrality metrics? Why is this the case? Please offer some potential explanations using specific nodes as examples.

e.g. For the collective intelligence graph...

e.g. For the artificial intelligence graph...

## Comparing the local properties of the two networks **(4 points)**

##### Think back to what you gleaned from your network visualizations in Lab 1. Do your results in this part of the assignment align with your expectations or do they surprise you? Please explain.

e.g. In Lab 1...

# PART II: Global Network Properties **(40 points)**

In this part, you will compute global properties of your network, such as subgroups, which provide a plethora of information to social network researchers. A variety of algorithms have been developed to identify and measure subgroups. You will use some of igraph's built-in tools to identify subgroups and central nodes for visual inspection.

For one of the collective **OR** artificial intelligence graphs:

## K-cores in your network **(6 points)**

##### What is a k-core? What insight does this k-core decomposition method provide? What is the highest/maximum level, k, of cores present in your network?

e.g., A k-core is...

```{r}
#| echo: false
#| output: false
#| message: false
#| warning: false

# To go back to igraph analysis, you might neet to detach 'statnet' first
# before recalling 'igraph'
# detach('package:statnet', unload = TRUE)
# library(igraph)

## calculate k-cores

# Make sure to only include code for the graph that you are interpreting. 
# Delete or comment out the code for the other graph.

print("AI Graph Analysis")
kcore_gpt <-
  giantGraph_gpt |>  igraph::graph.coreness()
kcore_gpt ## show the results of k-core decomposition

print("CI Graph Analysis")
kcore_hmn <-
  giantGraph_hmn |>  igraph::graph.coreness()
kcore_hmn ## show the results of k-core decomposition
```

##### Visualize your network using k-core decomposition. In a few sentences, discuss your interpretation of the visualizations. Do the results of k-core decomposition make sense based on your expectations of the network?

```{r}
#| echo: false

## Plot a graph colored by the k-core decomposition results

# Make sure to only include code for the graph that you are interpreting. 
# Delete or comment out the code for the other graph.

giantGraph_gpt %>%
  plot(
    .,
    layout = layout_with_gem(.),
    # layout = layout_with_sugiyama(.),
    edge.arrow.size = .3,
    vertex.size = 4,
    vertex.label = NA,
    vertex.color = adjustcolor(graph.coreness(.), alpha.f = .3),
    vertex.label.cex = .5,
    vertex.label.color = 'black',
    mark.groups = by(seq_along(graph.coreness(.)), graph.coreness(.), invisible),
    mark.shape = 1 / 4,
    mark.col = rainbow(length(unique(graph.coreness(
      .
    ))), alpha = .1),
    mark.border = NA,
    main="AI graph k-cores"
  )

giantGraph_hmn %>%
  plot(
    .,
    layout = layout_with_gem(.),
    # layout = layout_with_sugiyama(.),
    edge.arrow.size = .3,
    vertex.size = 4,
    vertex.label = NA,
    vertex.color = adjustcolor(graph.coreness(.), alpha.f = .3),
    vertex.label.cex = .5,
    vertex.label.color = 'black',
    mark.groups = by(seq_along(graph.coreness(.)), graph.coreness(.), invisible),
    mark.shape = 1 / 4,
    mark.col = rainbow(length(unique(graph.coreness(
      .
    ))), alpha = .1),
    mark.border = NA,
    main="CI graph k-cores"
  )
```

e.g., In my network...

## Community detection in your network **(10 points)**

##### Pick one community detection algorithm to run on your network. Which community detection algorithm did you choose and why?

```{r}
# Make sure to only include code for the graph that you are interpreting. 
# Delete or comment out the code for the other graph.

# below is using Newman-Girvan Algorithm (2003)

# if communities do not make sense to you, replace with your choice
# e.g., cluster_infomap, cluster_walktrap etc.
cluster_gpt <- giantGraph_gpt |>  igraph::cluster_edge_betweenness()
cluster_hmn <- giantGraph_hmn |>  igraph::cluster_edge_betweenness()

## if you want to test an algorithm designed for a directed graph, try:
# cluster <- giantGraph_gpt %>% cluster_walktrap()
# cluster <- giantGraph_hmn %>% cluster_walktrap()

# if you're curious, you can look at how each node was affiliated with a different community 
# membership(cluster_gpt)   # affiliation list
# membership(cluster_hmn)   # affiliation list
```

e.g., The algorithm I selected...

##### How many communities have been created in your network? What is the size of the largest community?

```{r}
#| echo: false

# Make sure to only include code for the graph that you are interpreting. 
# Delete or comment out the code for the other graph.

# Find the number of clusters
print("AI Graph Clusters")
length(cluster_gpt) # number of clusters
# Find the size of each cluster
# Note that communities with one node are isolates, or have only a single tie
sizes(cluster_gpt)

# Perform the same steps for the collective intelligence network
print("CI Graph Clusters")
length(cluster_hmn) # number of clusters
sizes(cluster_hmn) 
```

e.g., There were...

##### For your network, what might a community of nodes potentially have in common? Do these align with the topic modeling communities you visualized in Lab 1?

e.g., A community of nodes...

##### What is a modularity score? Define and interpret the modularity score of your graph.

```{r}
#| echo: false

# Make sure to only include code for the graph that you are interpreting. 
# Delete or comment out the code for the other graph.

# modularity measure
print("AI Modularity")
igraph::modularity(cluster_gpt)

print("CI Modularity")
igraph::modularity(cluster_hmn)
```

e.g., The modularity score of my results...

##### Plot the communities! What information does this layout convey? Are the communities well-separated or is there a great deal of overlap? Describe the actors between any components and cliques (i.e., brokers). What are common features of these actors?

```{r}
#| echo: false

# Visualize clusters - that puts colored blobs around the nodes in the same community.
# You may want to remove vertex.label=NA to figure out what terms are clustered.

# Make sure to only include code for the graph that you are interpreting. 
# Delete or comment out the code for the other graph.
cluster_gpt %>% plot(
  .,
  giantGraph_gpt,
  # layout = layout_with_gem(.),
  layout = layout_with_fr(giantGraph_gpt),
  edge.arrow.size = .3,
  vertex.size = 4,
  vertex.label = NA,
  vertex.color = adjustcolor(membership(.), alpha.f = .3),
  vertex.label.cex = .5,
  vertex.label.color = 'black',
  mark.groups = by(seq_along(membership(.)), membership(.), invisible),
  mark.shape = 1 / 4,
  mark.col = rainbow(length(.), alpha = .1),
  mark.border = NA,
  main = "AI Graph Communities"
)

cluster_hmn %>% plot(
  .,
  giantGraph_hmn,
  # layout = layout_with_gem(.),
  layout = layout_with_fr(giantGraph_hmn),
  edge.arrow.size = .3,
  vertex.size = 4,
  vertex.label = NA,
  vertex.color = adjustcolor(membership(.), alpha.f = .3),
  vertex.label.cex = .5,
  vertex.label.color = 'black',
  mark.groups = by(seq_along(membership(.)), membership(.), invisible),
  mark.shape = 1 / 4,
  mark.col = rainbow(length(.), alpha = .1),
  mark.border = NA,
  main = "CI Graph Communities"
)
```

e.g., This layout...

## Scale-free properties of your network **(8 points)**

##### Present and interpret the degree distribution of your network.

```{r}
#| echo: false

# Make sure to only include code for the graph that you are interpreting. 
# Delete or comment out the code for the other graph.

# Examine the degree distribution
data.frame(density = giantGraph_gpt %>% 
             degree_distribution()) |> 
  dplyr::mutate(degree = row_number()) |> 
  ggplot(aes(x = degree, y = density)) +
  geom_bar(stat = "identity") +
  ggtitle("Degree Distribution for GPT") +
  ylab("Density") +
  xlab("Degree")+
  theme_minimal()

data.frame(density = giantGraph_hmn %>% 
             degree_distribution()) |> 
  dplyr::mutate(degree = row_number()) |> 
  ggplot(aes(x = degree, y = density)) +
  geom_bar(stat = "identity") +
  ggtitle("Degree Distribution for Human") +
  ylab("Density") +
  xlab("Degree")+
  theme_minimal()
```

e.g., The degree distribution...

##### Present and interpret the log-log plot of your network.

```{r}
#| echo: false

# Make sure to only include code for the graph that you are interpreting. 
# Delete or comment out the code for the other graph.

# CCDF - Complementary Cumulative Distribution Function
# Plot a log-log plot of in-degree distribution
data.frame(density = giantGraph_gpt |>  
             degree_distribution(cumulative = TRUE)) |> 
  dplyr::mutate(degree = row_number()) |>
  ggplot(aes(x = degree, y = density)) +
  geom_line() +
  scale_x_log10() +
  scale_y_log10() +
  ggtitle("Log-Log Plot of Degree for GPT") +
  ylab("CCDF") +
  xlab("Degree")+
  theme_minimal()


data.frame(density = giantGraph_hmn |>  
             degree_distribution(cumulative = TRUE)) |> 
  dplyr::mutate(degree = row_number()) |>
  ggplot(aes(x = degree, y = density)) +
  geom_line() +
  scale_x_log10() +
  scale_y_log10() +
  ggtitle("Log-Log Plot of Degree for Human") +
  ylab("CCDF") +
  xlab("Degree")+
  theme_minimal()
```

e.g., The log-log plot...

##### Fit a power law to the degree distribution and interpret the results. Make sure to interpret the estimate of the slope (the alpha value) and the p-value (KS.p).

::: {.callout-note style="color: purple"}
Tip: KS.p less than 0.05 provides evidence that the empirical data does not fit with the power-law distribution.
:::

```{r}
#| echo: false

# Make sure to only include code for the graph that you are interpreting. 
# Delete or comment out the code for the other graph.

set.seed(1) # This should result in consistent outputs from stochastic functions

# First fit a power law to the degree distribution of your network
# The output of the fit_power_law() function tells us what the exponent of the power law is ($alpha)
# and the log-likelihood of the parameters used to fit the power law distribution ($logLik)

print("AI power law")
power_gpt <- giantGraph_gpt |> 
  degree_distribution() |> 
  fit_power_law()
power_gpt

print("CI power law")
power_hmn <- giantGraph_hmn |> 
  degree_distribution() |> 
  fit_power_law()
power_hmn

## now create a random power law distribution using the appropriate alpha from your network
test_power_dist_gpt = poweRlaw::rpldis(200, xmin = 1, alpha = power_gpt$alpha)-1  

test_power_dist_hmn = poweRlaw::rpldis(200, xmin = 1, alpha = power_hmn$alpha)-1  

# finally we will do a Kolmogov-Smirnov test between your network's degree distribution
# and the randomly generated power law distribution. This tests whether the given degree 
# distribution could have been drawn from the fitted power law distribution.

print("AI power law significance test")
giantGraph_gpt |> 
  degree_distribution() |> 
  ks.test(test_power_dist_gpt)

print("CI power law significance test")
giantGraph_hmn |> 
  degree_distribution() |> 
  ks.test(test_power_dist_hmn)
```

e.g., The power law...

## Small world properties of your network **(8 points)**

::: {.callout-note style="color: purple"}
That is not a statistics class, but in the next chunk you will have to make an important statistical decision.

Choose to use either 'less' or 'greater' as the alternative hypothesis, based on your results (you want to use the one that generates the smaller p-value).

For curious ones, refer to [this article](http://www.stat.columbia.edu/~gelman/research/published/incrementalism_3.pdf).
:::

##### Plot the observed and simulated values for the global clustering coefficient based on the original network and 1,000 randomly shuffled networks. Conduct a t-test to check whether the observed value is statistically different from the simulated distribution.

::: {.callout-note style="color: purple"}
Step 1: First we will generate 1000 randomly shuffled networks.
:::

```{r}
#| echo: false

# Make sure to only include code for the graph that you are interpreting. 
# Delete or comment out the code for the other graph.

ntrials <- 1000 ## set the number of repetitions

# First we need to create variables store the values from our simulations
cl.rg_gpt <- numeric(ntrials) ## create an estimated value holder for clustering coefficient
apl.rg_gpt <- numeric(ntrials) ## create an estimated value holder for average path length

# Now we use the rewire function from igraph to randomly rewire edges while
# preserving the original graph's degree distribution
for (i in (1:ntrials)) {
  g.rg <- rewire(giantGraph_gpt, keeping_degseq(niter = 100))
  cl.rg_gpt[i] <- transitivity(g.rg, type = 'average')
  apl.rg_gpt[i] <- mean_distance(g.rg)
}

# Perform the same steps for the human graph
cl.rg_hmn <- numeric(ntrials)
apl.rg_hmn <- numeric(ntrials)

for (i in (1:ntrials)) {
  g.rg <- rewire(giantGraph_hmn, keeping_degseq(niter = 100))
  cl.rg_hmn[i] <- transitivity(g.rg, type = 'average')
  apl.rg_hmn[i] <- mean_distance(g.rg)
}
```

::: {.callout-note style="color: purple"}
Step 2: Now we will plot the clustering coefficient values and average path lengths from our 1000 rewired graphs in a histogram. We will use a red line to denote the values of our observed clustering coefficient and average path length.
:::

```{r}
#| echo: false
# plot a histogram of simulated values for clustering coefficient + the observed value
tibble(simulated_clustering_coef = cl.rg_gpt,
       observed_clustering_coef = giantGraph_gpt |> igraph::transitivity(graph = _, type = 'average')) |> 
ggplot(aes(x = simulated_clustering_coef))+
  geom_histogram(bins = 100)+
  geom_vline(aes(xintercept = observed_clustering_coef), color = "red", linetype = "dashed")+ # the line indicates the mean value of clustering coefficient for your network
  geom_label(
    aes(x = observed_clustering_coef, y = 30), 
    label = "Observed Clustering Coefficient", vjust = -1, color = "red", angle = 90)+
  geom_label(
    aes(x = mean(cl.rg_gpt), y = 50), 
    label = "Simulated Clustering Coefficients", vjust = -1, color = "black")+
  xlab("Clustering Coefficient")+
  ylab("Count")+
  ggtitle("1. Histogram of Clustering Coefficient for AI Graph")+
  theme_minimal()

# repeat the code above on the collective intelligence network
tibble(simulated_clustering_coef = cl.rg_hmn,
       observed_clustering_coef = giantGraph_hmn |> igraph::transitivity(graph = _, type = 'average')) |> 
ggplot(aes(x = simulated_clustering_coef))+
  geom_histogram(bins = 100)+
  geom_vline(aes(xintercept = observed_clustering_coef), color = "red", linetype = "dashed")+ # the line indicates the mean value of clustering coefficient for your network
  geom_label(
    aes(x = observed_clustering_coef, y = 30), 
    label = "Observed Clustering Coefficient", vjust = -1, color = "red", angle = 90)+
  geom_label(
    aes(x = mean(cl.rg_hmn), y = 50), 
    label = "Simulated Clustering Coefficients", vjust = -1, color = "black")+
  xlab("Clustering Coefficient")+
  ylab("Count")+
  ggtitle("2. Histogram of Clustering Coefficient for Collective Intelligence Graph")+
  theme_minimal()
```

::: {.callout-note style="color: purple"}
Step 3: We will use a t-test to determine whether the observed value is statistically different from the simulated distribution. We are testing whether the mean of our simulated distributions are higher or lower than our observed values. You should be able to choose the correct direction for your t-test alternative hypothesis based on the histogram! In this case, selecting the alternative hypothesis "greater" means that the simulated means are greater than the observed value, whereas "less" means that the simulated means are less than the observed value.
:::

```{r}
#| echo: false

# this tests whether the observed value is statistically different from the simulated distribution
print("AI graph clustering coefficient t-test")
t.test(
  cl.rg_gpt,
  mu = giantGraph_gpt |> igraph::transitivity(type = 'average'),
  alternative = 'less'
) 

# you can also pick either 'less' or 'greater' based on your results
# (you want to use the one that generates the smaller p-value)

# repeat above for collective intelligence graph
print("CI graph clustering coefficient t-test")
t.test(
  cl.rg_hmn,
  mu = giantGraph_hmn |> igraph::transitivity(type = 'average'),
  alternative = 'greater'
)
```

```{r}
#| echo: false

# Now we will repeat these steps for the average path length
# plot a histogram of simulated values for average path length + the observed value
tibble(simulated_apl = apl.rg_gpt,
       observed_apl = giantGraph_gpt %>% igraph::mean_distance()) |> 
ggplot(aes(x = simulated_apl))+
  geom_histogram(bins = 100)+
    geom_label(
    aes(x = mean(simulated_apl), y = 10), 
    label = "Simulated Average Path Lengths", color = "black")+
  geom_vline(aes(xintercept = observed_apl), color = "cyan4", linetype = "dashed")+ # the line indicates the mean value of clustering coefficient for your network
  geom_label(
    aes(x = observed_apl, y = 30), 
    label = "Observed Average Path Length", vjust = -1, color = "cyan4", angle = 90)+
  xlab("Clustering Coefficient")+
  ylab("Count")+
  ggtitle("3. Histogram of Average Path Lenth for AI Graph")+
  theme_minimal()

# this tests whether the observed value is statistically different from the simulated distribution
print("AI graph average path length t-test")
t.test(apl.rg_gpt,
       mu = giantGraph_gpt |>  mean_distance(),
       alternative = 'greater') 
## pick either 'less' or 'greater' based on your results
## (you want to use the one that generates the smaller p-value)


# repeat above for collective intelligence graph
tibble(simulated_apl = apl.rg_hmn,
       observed_apl = giantGraph_hmn %>% igraph::mean_distance()) |> 
ggplot(aes(x = simulated_apl))+
  geom_histogram(bins = 100)+
    geom_label(
    aes(x = mean(simulated_apl), y = 10), 
    label = "Simulated Average Path Lengths", color = "black")+
  geom_vline(aes(xintercept = observed_apl), color = "cyan4", linetype = "dashed")+ # the line indicates the mean value of clustering coefficient for your network
  geom_label(
    aes(x = observed_apl, y = 30), 
    label = "Observed Average Path Length", vjust = -1, color = "cyan4", angle = 90)+
  xlab("Clustering Coefficient")+
  ylab("Count")+
  ggtitle("4. Histogram of Average Path Lenth for CI Graph")+
  theme_minimal()

print("CI graph average path length t-test")
t.test(apl.rg_hmn,
       mu = giantGraph_hmn |>  mean_distance(),
       alternative = 'greater')

```

##### Based on these results would you conclude that the observed network demonstrates small world properties? If so, why? If not, why not?

## Major findings **(8 points)**

##### In two or three paragraphs, discuss your major findings based on all the analyses you've done between Lab 1 and Lab 2. Your answer here will be evaluated based on depth and comprehensiveness. Thus, you're encouraged to utilize extra information to answer this question. For instance, you can take a look at your original text data. Similarly, if you need more insights from your network, feel free to run other types of analyses based on your data collection.

...

## Disclose AI Use

I used ... to generate ... for this lab

------------------------------------------------------------------------


Check your submission for grammar - points may be deducted for lack of clarity.

Click 'Render' button at the top of the screen, or press cmd + shift + k. Note. It might take some time for you computer to render this document as a PDF, since it will be running all code chunks.

Deliverables to submit on Canvas:

1.  Your report as a .pdf file
2.  Your code as a .qmd file
3.  Your data as a .RData file

Please upload each file separately -- do not upload as a zip file! *(Please)*
